{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNAfqm3R/vhULzKhBx5R2Hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AiProcess/Pendulum_PPO/blob/main/main_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxpKJ3fFt4dc",
        "outputId": "34f04930-d7ee-4c6b-8456-880cd8526c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzFFTccouXYw",
        "outputId": "e1550e01-7b7c-4756-c2b2-c2e7fba567a7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gdrive\tsample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd gdrive/MyDrive/colab_projects/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLR_qCXCu5DD",
        "outputId": "89822ad5-d62d-4b51-c504-c374d8394ade"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/colab_projects\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/AiProcess/Pendulum_PPO.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNYPI602u81t",
        "outputId": "2c36b3d6-f777-4160-94d0-fef0923048a3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Pendulum_PPO'...\n",
            "remote: Enumerating objects: 54, done.\u001b[K\n",
            "remote: Counting objects: 100% (54/54), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 54 (delta 24), reused 39 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (54/54), 65.10 KiB | 2.60 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYz2C9flvqEc",
        "outputId": "85de8567-03b9-47b7-e04d-5f45503afa3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pendulum_PPO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd Pendulum_PPO/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwXWH-DXvroY",
        "outputId": "dab2c754-00a6-4422-a909-2852ce7f26e9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/colab_projects/Pendulum_PPO\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueOOLmuRwRaU",
        "outputId": "42aadc10-cc67-41ee-ac67-52890d2f31d8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Agent.py  Environment.py  log  main.ipynb  main.py  __pycache__  README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchrl"
      ],
      "metadata": {
        "id": "MBvSfrdB2Ord"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym[mujoco]"
      ],
      "metadata": {
        "id": "eOtY8yPd2nZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install av"
      ],
      "metadata": {
        "id": "y6aHBI-N4jT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y xvfb\n",
        "!pip install pyvirtualdisplay"
      ],
      "metadata": {
        "id": "Cxp7r6b520w-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyvirtualdisplay import Display\n",
        "\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()"
      ],
      "metadata": {
        "id": "Zq1zIkIi4Ll6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python main.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlRC7lTiwS0m",
        "outputId": "a6e3b212-2f28-4865-a563-4ad4d7014619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected device is cuda\n",
            "2024-11-22 12:50:33,471 [torchrl][INFO] check_env_specs succeeded!\n",
            "2024-11-22 12:50:33,540 [torchrl][INFO] check_env_specs succeeded!\n",
            "Running policy: TensorDict(\n",
            "    fields={\n",
            "        action: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        loc: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        observation: Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        sample_log_prob: Tensor(shape=torch.Size([]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        scale: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "Running value: TensorDict(\n",
            "    fields={\n",
            "        done: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        observation: Tensor(shape=torch.Size([11]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        state_value: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.float32, is_shared=True),\n",
            "        step_count: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.int64, is_shared=True),\n",
            "        terminated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True),\n",
            "        truncated: Tensor(shape=torch.Size([1]), device=cuda:0, dtype=torch.bool, is_shared=True)},\n",
            "    batch_size=torch.Size([]),\n",
            "    device=cuda:0,\n",
            "    is_shared=True)\n",
            "eval cumulative reward:  9348.7471 (init:  101.6183), eval step-count: 999, average reward= 9.3336 (init= 9.0891), step count (max): 588, lr policy:  0.0003:   7% 74000/1000000 [04:56<1:04:54, 237.76it/s]"
          ]
        }
      ]
    }
  ]
}